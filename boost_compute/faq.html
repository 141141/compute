<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=US-ASCII">
<title>Frequently Asked Questions</title>
<link rel="stylesheet" href="../boostbook.css" type="text/css">
<meta name="generator" content="DocBook XSL Stylesheets V1.75.2">
<link rel="home" href="../index.html" title="Chapter&#160;1.&#160;Boost.Compute">
<link rel="up" href="../index.html" title="Chapter&#160;1.&#160;Boost.Compute">
<link rel="prev" href="../boost/compute/wait_list.html" title="Class wait_list">
</head>
<body bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF">
<div class="spirit-nav">
<a accesskey="p" href="../boost/compute/wait_list.html"><img src="../images/prev.png" alt="Prev"></a><a accesskey="u" href="../index.html"><img src="../images/up.png" alt="Up"></a><a accesskey="h" href="../index.html"><img src="../images/home.png" alt="Home"></a>
</div>
<div class="section">
<div class="titlepage"><div><div><h2 class="title" style="clear: both">
<a name="boost_compute.faq"></a><a class="link" href="faq.html" title="Frequently Asked Questions">Frequently Asked Questions</a>
</h2></div></div></div>
<h4>
<a name="boost_compute.faq.h0"></a>
      <span><a name="boost_compute.faq.how_do_i_report_a_bug__issue__or_feature_request_"></a></span><a class="link" href="faq.html#boost_compute.faq.how_do_i_report_a_bug__issue__or_feature_request_">How
      do I report a bug, issue, or feature request?</a>
    </h4>
<p>
      Please submit an issue on the GitHub issue tracker at <a href="https://github.com/kylelutz/compute/issues" target="_top">https://github.com/kylelutz/compute/issues</a>.
    </p>
<h4>
<a name="boost_compute.faq.h1"></a>
      <span><a name="boost_compute.faq.where_can_i_find_more_documentation_"></a></span><a class="link" href="faq.html#boost_compute.faq.where_can_i_find_more_documentation_">Where can
      I find more documentation?</a>
    </h4>
<div class="itemizedlist"><ul class="itemizedlist" type="disc">
<li class="listitem">
          The main documentation is here: <a href="http://kylelutz.github.io/compute/" target="_top">http://kylelutz.github.io/compute/</a>
        </li>
<li class="listitem">
          The README is here: <a href="https://github.com/kylelutz/compute/blob/master/README.md" target="_top">https://github.com/kylelutz/compute/blob/master/README.md</a>
        </li>
<li class="listitem">
          The wiki is here: <a href="https://github.com/kylelutz/compute/wiki" target="_top">https://github.com/kylelutz/compute/wiki</a>
        </li>
<li class="listitem">
          The contributor guide is here: <a href="https://github.com/kylelutz/compute/blob/master/CONTRIBUTING.md" target="_top">https://github.com/kylelutz/compute/blob/master/CONTRIBUTING.md</a>
        </li>
<li class="listitem">
          The header reference is here: <a href="http://kylelutz.github.io/compute/compute/reference.html#header_reference" target="_top">http://kylelutz.github.io/compute/compute/reference.html#header_reference</a>
        </li>
</ul></div>
<h4>
<a name="boost_compute.faq.h2"></a>
      <span><a name="boost_compute.faq.what_compute_devices__e_g__gpus__are_supported_"></a></span><a class="link" href="faq.html#boost_compute.faq.what_compute_devices__e_g__gpus__are_supported_">What
      compute devices (e.g. GPUs) are supported?</a>
    </h4>
<p>
      Any device which implements the OpenCL standard is supported. This includes
      GPUs from NVIDIA, AMD, and Intel as well as CPUs from AMD and Intel and other
      accelerator cards such as the Xeon Phi.
    </p>
<h4>
<a name="boost_compute.faq.h3"></a>
      <span><a name="boost_compute.faq.can_you_compare_boost_compute_to_other_gpgpu_libraries_such_as_thrust__bolt_and_vexcl_"></a></span><a class="link" href="faq.html#boost_compute.faq.can_you_compare_boost_compute_to_other_gpgpu_libraries_such_as_thrust__bolt_and_vexcl_">Can
      you compare Boost.Compute to other GPGPU libraries such as Thrust, Bolt and
      VexCL?</a>
    </h4>
<p>
      Thrust implements a C++ STL-like API for GPUs and CPUs. It is built with multiple
      backends. NVIDIA GPUs use the CUDA backend and multi-core CPUs can use the
      Intel TBB or OpenMP backends. However, thrust will not work with AMD graphics
      cards or other lesser-known accelerators. I feel Boost.Compute is superior
      in that it uses the vendor-neutral OpenCL library to achieve portability across
      all types of compute devices.
    </p>
<p>
      Bolt is an AMD specific C++ wrapper around the OpenCL API which extends the
      C99-based OpenCL language to support C++ features (most notably templates).
      It is similar to NVIDIA's Thrust library and shares the same failure, lack
      of portability.
    </p>
<p>
      VexCL is an expression-template based linear-algebra library for OpenCL. The
      aims and scope are a bit different from the Boost Compute library. VexCL is
      closer in nature to the Eigen library while Boost.Compute is closer to the
      C++ standard library. I don't feel that Boost.Compute really fills the same
      role as VexCL and in fact VexCL could be built on top of Boost.Compute.
    </p>
<h4>
<a name="boost_compute.faq.h4"></a>
      <span><a name="boost_compute.faq.why_not_write_just_write_a_new_opencl_back_end_for_thrust_"></a></span><a class="link" href="faq.html#boost_compute.faq.why_not_write_just_write_a_new_opencl_back_end_for_thrust_">Why
      not write just write a new OpenCL back-end for Thrust?</a>
    </h4>
<p>
      It would not be possible to provide the same API that Thrust expects for OpenCL.
      The fundamental reason is that functions/functors passed to Thrust algorithms
      are actual compiled C++ functions whereas for Boost.Compute these form expression
      objects which are then translated into C99 code which is then compiled for
      OpenCL.
    </p>
<h4>
<a name="boost_compute.faq.h5"></a>
      <span><a name="boost_compute.faq.why_not_target_cuda_and_or_support_multiple_back_ends_"></a></span><a class="link" href="faq.html#boost_compute.faq.why_not_target_cuda_and_or_support_multiple_back_ends_">Why
      not target CUDA and/or support multiple back-ends?</a>
    </h4>
<p>
      CUDA and OpenCL are two very different technologies. OpenCL works by compiling
      C99 code at run-time to generate kernel objects which can then be executed
      on the GPU. CUDA, on the other hand, works by compiling its kernels using a
      special compiler (nvcc) which then produces binaries which can executed on
      the GPU.
    </p>
<p>
      OpenCL already has multiple implementations which allow it to be used on a
      variety of platforms (e.g. NVIDIA GPUs, Intel CPUs, etc.). I feel that adding
      another abstraction level within Boost.Compute would only complicate and bloat
      the library.
    </p>
<h4>
<a name="boost_compute.faq.h6"></a>
      <span><a name="boost_compute.faq.is_it_possible_to_use_ordinary_c___functions_functors_or_c__11__lambdas_with_boost_compute_"></a></span><a class="link" href="faq.html#boost_compute.faq.is_it_possible_to_use_ordinary_c___functions_functors_or_c__11__lambdas_with_boost_compute_">Is
      it possible to use ordinary C++ functions/functors or C++11 lambdas with Boost.Compute?</a>
    </h4>
<p>
      Unfortunately no. OpenCL relies on having C99 source code available at run-time
      in order to execute code on the GPU. Thus compiled C++ functions or C++11 lambdas
      cannot simply be passed to the OpenCL environment to be executed on the GPU.
    </p>
<p>
      This is the reason why I wrote the Boost.Compute lambda library. Basically
      it takes C++ lambda expressions (e.g. _1 * sqrt(_1) + 4) and transforms them
      into C99 source code fragments (e.g. &#8220;input[i] * sqrt(input[i]) + 4)&#8221;)
      which are then passed to the Boost.Compute STL-style algorithms for execution.
      While not perfect, it allows the user to write code closer to C++ that still
      can be executed through OpenCL.
    </p>
<p>
      Also check out the BOOST_COMPUTE_FUNCTION() macro which allows OpenCL functions
      to be defined inline with C++ code. An example can be found in the monte_carlo
      example code.
    </p>
<h4>
<a name="boost_compute.faq.h7"></a>
      <span><a name="boost_compute.faq.what_is_the_command_queue_argument_that_appears_in_all_of_the_algorithms_"></a></span><a class="link" href="faq.html#boost_compute.faq.what_is_the_command_queue_argument_that_appears_in_all_of_the_algorithms_">What
      is the command_queue argument that appears in all of the algorithms?</a>
    </h4>
<p>
      Command queues specify the context and device for the algorithm's execution.
      For all of the standard algorithms the command_queue parameter is optional.
      If not provided, a default command_queue will be created for the default GPU
      device and the algorithm will be executed there.
    </p>
<h4>
<a name="boost_compute.faq.h8"></a>
      <span><a name="boost_compute.faq.how_can_i_contribute_"></a></span><a class="link" href="faq.html#boost_compute.faq.how_can_i_contribute_">How
      can I contribute?</a>
    </h4>
<p>
      We are actively seeking additional C++ developers with experience in GPGPU
      and parallel-computing.
    </p>
<p>
      Please send an email to Kyle Lutz (kyle.r.lutz@gmail.com) for more information.
    </p>
<p>
      Also see the <a href="https://github.com/kylelutz/compute/blob/master/CONTRIBUTING.md" target="_top">contributor
      guide</a> and check out the list of issues at: <a href="https://github.com/kylelutz/compute/issues" target="_top">https://github.com/kylelutz/compute/issues</a>.
    </p>
</div>
<table xmlns:rev="http://www.cs.rpi.edu/~gregod/boost/tools/doc/revision" width="100%"><tr>
<td align="left"></td>
<td align="right"><div class="copyright-footer">Copyright &#169; 2013, 2014 Kyle Lutz<p>
        Distributed under the Boost Software License, Version 1.0. (See accompanying
        file LICENSE_1_0.txt or copy at <a href="http://www.boost.org/LICENSE_1_0.txt" target="_top">http://www.boost.org/LICENSE_1_0.txt</a>)
      </p>
</div></td>
</tr></table>
<hr>
<div class="spirit-nav">
<a accesskey="p" href="../boost/compute/wait_list.html"><img src="../images/prev.png" alt="Prev"></a><a accesskey="u" href="../index.html"><img src="../images/up.png" alt="Up"></a><a accesskey="h" href="../index.html"><img src="../images/home.png" alt="Home"></a>
</div>
</body>
</html>
